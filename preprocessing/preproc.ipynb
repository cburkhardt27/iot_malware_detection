{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_43 = \"/Users/yujinkwon/Documents/CS334/Final_project/train_data_500k 1.csv\"\n",
    "capture_34 = \"/Users/yujinkwon/Documents/CS334/Final_project/opt/Malware-Project/BigDataset/IoTScenarios/CTU-IoT-Malware-Capture-34-1/bro/conn.log.labeled\"\n",
    "capture_60 = \"/Users/yujinkwon/Documents/CS334/Final_project/iot_malware_detection/data/60_train_data_500k.csv\"\n",
    "capture_35 = '/Users/yujinkwon/Documents/CS334/Final_project/iot_malware_detection/data/35_train_data_500k.csv'\n",
    "capture_48 = '/Users/yujinkwon/Documents/CS334/Final_project/iot_malware_detection/data/48_train_data_500k.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data + Typecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df43 = pd.read_table(capture_48, skiprows = 2, delimiter='\\t', header =None) # for capture_43\n",
    "# df43 = pd.read_table(capture_34, skiprows = 8, delimiter='\\t', header =None) # for capture_34\n",
    "df43.columns = [\n",
    "    'ts',\t\n",
    "    'uid',\n",
    "    'id.orig_h',\n",
    "    'id.orig_p',\n",
    "    'id.resp_h',\n",
    "    'id.resp_p',\n",
    "    'proto',\n",
    "    'service',\n",
    "    'duration',\n",
    "    'orig_bytes',\n",
    "    'resp_bytes',\n",
    "    'conn_state',\n",
    "    'local_orig',\n",
    "    'local_resp',\n",
    "    'missed_bytes',\n",
    "    'history',\n",
    "    'orig_pkts',\n",
    "    'orig_ip_bytes',\n",
    "    'resp_pkts',\n",
    "    'resp_ip_bytes',\n",
    "    'last_col'\n",
    "]\n",
    "\n",
    "df43[['tunnel_parents', 'label', 'detailed-label']] = df43['last_col'].str.split(expand=True)\n",
    "df43.drop('last_col', axis=1, inplace=True)\n",
    "df43.drop('ts', axis=1, inplace=True)\n",
    "df43.drop('uid', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id.orig_h          object\n",
       "id.orig_p           int64\n",
       "id.resp_h          object\n",
       "id.resp_p           Int64\n",
       "proto              object\n",
       "service            object\n",
       "duration          float64\n",
       "orig_bytes          Int64\n",
       "resp_bytes          Int64\n",
       "conn_state         object\n",
       "local_orig           bool\n",
       "local_resp           bool\n",
       "missed_bytes        int64\n",
       "history            object\n",
       "orig_pkts           Int64\n",
       "orig_ip_bytes       Int64\n",
       "resp_pkts           Int64\n",
       "resp_ip_bytes       Int64\n",
       "tunnel_parents    float64\n",
       "label              object\n",
       "detailed-label     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time\tstring\taddr\tport\taddr\tport\tenum\tstring\tinterval\tcount\tcount\tstring\tbool\tbool\tcount\tstring\tcount\tcount\tcount\tcount\tset[string]   string   string\n",
    "# df43['ts'] = pd.to_datetime(df43['ts'], unit = 's')\n",
    "\n",
    "\n",
    "# Replace 'NULL' with NaN (a common representation for missing values)\n",
    "df43.replace('-', 'NULL', inplace=True)\n",
    "df43.replace('NULL', np.nan, inplace=True)\n",
    "df43.replace('NaT', np.nan, inplace=True)\n",
    "df43.replace('NaN', np.nan, inplace=True)\n",
    "\n",
    "# Type casting features as correct type\n",
    "\n",
    "column_data = pd.to_numeric('duration', errors='coerce')\n",
    "df43['local_orig'] = df43['local_orig'].astype(bool)\n",
    "df43['local_resp'] = df43['local_resp'].astype(bool)\n",
    "df43['orig_bytes'] = df43['orig_bytes'].astype('Int64')\n",
    "df43['resp_bytes'] = df43['resp_bytes'].astype('Int64')\n",
    "df43['duration'] = df43['duration'].astype(float)\n",
    "df43['resp_bytes'] = df43['resp_bytes'].astype('Int64')\n",
    "df43['id.resp_p'] = df43['id.resp_p'].astype('Int64')\n",
    "df43['orig_pkts'] = df43['orig_pkts'].astype('Int64')\n",
    "df43['resp_pkts'] = df43['resp_pkts'].astype('Int64')\n",
    "df43['orig_ip_bytes'] = df43['orig_ip_bytes'].astype('Int64')\n",
    "df43['resp_ip_bytes'] = pd.to_numeric(df43['resp_ip_bytes'], errors='coerce')\n",
    "df43['resp_ip_bytes'] = df43['resp_ip_bytes'].astype('Int64')\n",
    "\n",
    "df43_clean = df43.copy()\n",
    "df43.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying port --> integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding id.orig_h, id.resp_h as Int64\n",
    "\n",
    "def port_to_int(df, col_name): \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for pnt in range(len(df43[col_name])):\n",
    "        if not pd.isna(df43.at[pnt, col_name]):\n",
    "            x = str(df43.at[pnt, col_name])  # Convert the numerical value to a string\n",
    "            z = ''\n",
    "            parts = x.split('.')\n",
    "            \n",
    "            # Process each part of the IP address-like value\n",
    "            for prt in range(4):\n",
    "                if len(parts[prt]) == 3:\n",
    "                    z = parts[prt] + z\n",
    "                elif len(parts[prt]) == 2:\n",
    "                    z = '0' + parts[prt] + z\n",
    "                else:\n",
    "                    z = '00' + parts[prt] + z\n",
    "            \n",
    "            # Update the DataFrame with the processed value\n",
    "            df43.at[pnt, col_name] = int(z)\n",
    "    \n",
    "    \n",
    "    return df43\n",
    "\n",
    "df43 = port_to_int(df43, 'id.orig_h')\n",
    "df43 = port_to_int(df43, 'id.resp_h')\n",
    "df43['id.orig_h'] = df43['id.orig_h'].astype('Int64')\n",
    "df43['id.resp_h'] = df43['id.resp_h'].astype('Int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id.orig_h           Int64\n",
       "id.orig_p           int64\n",
       "id.resp_h           Int64\n",
       "id.resp_p           Int64\n",
       "proto              object\n",
       "service            object\n",
       "duration          float64\n",
       "orig_bytes          Int64\n",
       "resp_bytes          Int64\n",
       "conn_state         object\n",
       "local_orig           bool\n",
       "local_resp           bool\n",
       "missed_bytes        int64\n",
       "history            object\n",
       "orig_pkts           Int64\n",
       "orig_ip_bytes       Int64\n",
       "resp_pkts           Int64\n",
       "resp_ip_bytes       Int64\n",
       "tunnel_parents    float64\n",
       "label              object\n",
       "detailed-label     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df43.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Catgegorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_unique_vals(data, col):\n",
    "#     \"\"\"\n",
    "#     input is 2d numpy array of data, col name\n",
    "#     returns unqiue vals in column\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Extract the specified column\n",
    "#     column_data = data[col]\n",
    "\n",
    "#     # Find unique values in the column\n",
    "#     unique_values = np.unique(column_data)\n",
    "\n",
    "#     # Create a mapping from unique values to encoded integers\n",
    "#     value_to_int_map = {value: index for index, value in enumerate(unique_values)}\n",
    "\n",
    "#     # Encode the entire column using the mapping\n",
    "#     encoded_column = np.vectorize(value_to_int_map.get)(column_data)  \n",
    "\n",
    "#     data[col] = encoded_column\n",
    "\n",
    "#     return data\n",
    "\n",
    "# def encode_label(data, col):\n",
    "#     label_column = data[col]\n",
    "\n",
    "#     # Encode 'Benign' as 0 and other values as 1 using boolean indexing\n",
    "#     label_column[label_column == 'Benign'] = 0\n",
    "#     label_column[label_column != 0] = 1\n",
    "\n",
    "#     # Print modified label column\n",
    "#     print(\"Modified label column:\")\n",
    "#     print(label_column)\n",
    "\n",
    "#     # Update data array with the modified label column\n",
    "#     data[col] = label_column.astype(np.int32)  # Convert to float if necessary\n",
    "\n",
    "#     return data\n",
    "\n",
    "# def encode_detailed_label(data, col):\n",
    "#     label_column = data[col]\n",
    "    \n",
    "#     # Encode 'Benign' as 0 and other values as 1 using boolean indexing\n",
    "#     label_column[label_column == '-'] = 0\n",
    "#     label_column[label_column == 'PartOfAHorizontalPortScan'] = 1\n",
    "#     label_column[label_column == 'Benign'] = 2\n",
    "#     label_column[label_column == 'Benign'] = 3\n",
    "#     label_column[label_column == 'Benign'] = 4\n",
    "#     label_column[label_column == 'Benign'] = 5\n",
    "#     label_column[label_column == 'Benign'] = 6\n",
    "#     label_column[label_column == 'Benign'] = 7\n",
    "#     # Print modified label column\n",
    "#     print(\"Modified label column:\")\n",
    "#     print(label_column)\n",
    "\n",
    "#     # Update data array with the modified label column\n",
    "#     data[col] = label_column.astype(np.int32)  # Convert to float if necessary\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(data, col):\n",
    "\n",
    "    # Encode 'Benign' as 0 and other values as 1 using boolean indexing\n",
    "    data.loc[data[col] == 'Benign', col] = 0\n",
    "    data.loc[data[col] != 0, col] =  1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_detailed_label(data, col):\n",
    "\n",
    "    # Encode Detialed label based on type of malicious attack\n",
    "    data.loc[data[col] == np.nan, col] = 0\n",
    "    data.loc[data[col] == 'PartOfAHorizontalPortScan', col] = 1\n",
    "    data.loc[data[col] == 'Okiru', col] = 2\n",
    "    data.loc[data[col] == 'C&C', col] = 3\n",
    "    data.loc[data[col] == 'DDoS', col] = 4\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_column(df, column_name):\n",
    "    \"\"\"\n",
    "    One-hot encodes the unique values in the specified column of a DataFrame.\n",
    "    df: The input DataFrame.\n",
    "    column_name: The name of the column to be one-hot encoded.\n",
    "    \n",
    "    Returns: DataFrame with the specified column one-hot encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the specified column\n",
    "    column_data = df[column_name]\n",
    "    \n",
    "    # Use pd.get_dummies to one-hot encode the column\n",
    "    one_hot_encoded = pd.get_dummies(column_data, prefix=column_name)\n",
    "    \n",
    "    # Concatenate the one-hot encoded columns with the original DataFrame\n",
    "    df_encoded = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    \n",
    "    # Drop the original column as it's no longer needed\n",
    "    df_encoded = df_encoded.drop(column_name, axis=1)\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto\n",
      "conn_state\n",
      "history\n",
      "service\n",
      "label\n",
      "detailed-label\n",
      "Index(['id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'duration',\n",
      "       'orig_bytes', 'resp_bytes', 'local_orig', 'local_resp', 'missed_bytes',\n",
      "       'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'label',\n",
      "       'detailed-label', 'proto_icmp', 'proto_tcp', 'proto_udp',\n",
      "       'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO',\n",
      "       'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_S0',\n",
      "       'conn_state_S1', 'conn_state_S2', 'conn_state_SF', 'conn_state_SH',\n",
      "       'history_D', 'history_Dd', 'history_F', 'history_R', 'history_S',\n",
      "       'history_SaR', 'history_ShADadfF', 'history_ShAF', 'history_ShAFr',\n",
      "       'history_ShAdDaR', 'history_ShAdDaTFf', 'history_ShAdDaTR',\n",
      "       'history_ShAdDaTRf', 'history_ShAdDaTfR', 'history_ShAdDafr',\n",
      "       'history_ShAdfr', 'history_ShAfFa', 'history_ShAfFr', 'history_ShAfdtF',\n",
      "       'history_ShAr', 'history_ShwA', 'history_ShwAr', 'history_Sr',\n",
      "       'service_dns', 'service_http'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "mod_column_list = ['proto', 'conn_state', 'history', 'service']\n",
    "\n",
    "# Drop Nan Columns     \n",
    "# Check if any column contains only NaN values\n",
    "columns_with_allnan = df43.columns[df43.isna().all()]\n",
    "df43 = df43.drop(columns=columns_with_allnan)\n",
    "\n",
    "for mod_column in mod_column_list:\n",
    "    if mod_column in columns_with_allnan:\n",
    "        continue\n",
    "\n",
    "    print(mod_column)\n",
    "    df43 = one_hot_encode_column(df43, mod_column)\n",
    "\n",
    "mod_column = 'label'\n",
    "print(mod_column)\n",
    "df43 = encode_label(df43, mod_column)\n",
    "\n",
    "mod_column = 'detailed-label'\n",
    "print(mod_column)\n",
    "df34 = encode_detailed_label(df43, mod_column)\n",
    "\n",
    "print(df34.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'duration', 'orig_bytes', 'resp_bytes',  'missed_bytes', 'orig_pkts',  'orig_ip_bytes',  'resp_pkts',  'resp_ip_bytes']\n",
    "\n",
    "for col in col_list:\n",
    "    # Replace NaN values with the median\n",
    "    median_value = df43[col].median()\n",
    "    df43[col] = df43[col].fillna(median_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Dataframe into file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train500k_preproc.csv\"\n",
    "df43.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id.orig_h           Int64\n",
    "# id.orig_p           int64\n",
    "# id.resp_h           Int64\n",
    "# id.resp_p           Int64\n",
    "# proto              object\n",
    "# service           float64\n",
    "# duration          float64\n",
    "# orig_bytes          Int64\n",
    "# resp_bytes          Int64\n",
    "# conn_state         object\n",
    "# local_orig           bool\n",
    "# local_resp           bool\n",
    "# missed_bytes        int64\n",
    "# history            object\n",
    "# orig_pkts           Int64\n",
    "# orig_ip_bytes       Int64\n",
    "# resp_pkts           Int64\n",
    "# resp_ip_bytes       Int64\n",
    "# tunnel_parents    float64\n",
    "# label              object\n",
    "# detailed-label     object\n",
    "# dtype: object\n",
    "\n",
    "# Find columns with 'Int64' dtype\n",
    "int_columns = df43.select_dtypes(include='Int64').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data df43\n",
    "yData = df43[['label','detailed-label']]\n",
    "xData = df43.copy().drop(['label','detailed-label'],axis=1)\n",
    "\n",
    "xData.to_csv(\"48_500Kre_xTrain.csv\",index=False)\n",
    "yData.to_csv(\"48_500Kre_yTrain.csv\",index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'id.orig_h' has 337 unique values:\n",
      "<IntegerArray>\n",
      "[200001168192, 252170115204,  89038112202, 129194188219, 154246045218,\n",
      " 166162150031,  33211174193, 130161054069, 200224175137,  92158120095,\n",
      " ...\n",
      " 227142191207, 137097146068,  30236184177,  61168140080,   1009009009,\n",
      "  62080197157,  85218125154,  69071231049,  36122072073,  24118068051]\n",
      "Length: 337, dtype: Int64\n",
      "------------------------\n",
      "Column 'id.orig_p' has 14121 unique values:\n",
      "[36926 45572 47844 ... 37164 55888  5353]\n",
      "------------------------\n",
      "Column 'id.resp_h' has 461491 unique values:\n",
      "<IntegerArray>\n",
      "[  4004004004,  13013013013,  25025025025,  26026026026,  37037037037,\n",
      "  42042042042,  50050050050,  61061061061,  67067067067,  78078078078,\n",
      " ...\n",
      " 251191221195, 253193223197,  84054070052, 103073089071, 104074090072,\n",
      " 109079095077, 115085101083, 119089105087, 120090106088, 121091107089]\n",
      "Length: 461491, dtype: Int64\n",
      "------------------------\n",
      "Column 'id.resp_p' has 26 unique values:\n",
      "<IntegerArray>\n",
      "[   23,    80,     0,   123,     1,    13,    10, 46814, 57378, 53946,     3,\n",
      " 40368, 48826,  5353, 54776, 39144, 33750, 42988, 46274, 38450, 46598, 34140,\n",
      " 44770, 49588, 60392, 47434]\n",
      "Length: 26, dtype: Int64\n",
      "------------------------\n",
      "Column 'duration' has 27745 unique values:\n",
      "[3.14171  3.141213 3.140229 ... 3.112197 3.160242 3.159547]\n",
      "------------------------\n",
      "Column 'orig_bytes' has 26 unique values:\n",
      "<IntegerArray>\n",
      "[  0, 148,  56,  96, 120, 136, 280, 421, 104, 240,  24, 900,  12, 112, 360,\n",
      " 272,  22, 424,  25, 415,  19,  16,  27,  31,  28, 576]\n",
      "Length: 26, dtype: Int64\n",
      "------------------------\n",
      "Column 'resp_bytes' has 20 unique values:\n",
      "<IntegerArray>\n",
      "[    0, 74766,    96,    38,    91,   240,   100,    87,    45,    37,   109,\n",
      "   610,   119,    27,    32,   151,   593,    95,   133,   576]\n",
      "Length: 20, dtype: Int64\n",
      "------------------------\n",
      "Column 'local_orig' has 1 unique values:\n",
      "[ True]\n",
      "------------------------\n",
      "Column 'local_resp' has 1 unique values:\n",
      "[ True]\n",
      "------------------------\n",
      "Column 'missed_bytes' has 1 unique values:\n",
      "[0]\n",
      "------------------------\n",
      "Column 'orig_pkts' has 23 unique values:\n",
      "<IntegerArray>\n",
      "[  6,   4, 110,   2,  40,  44,  18,  48,  10,  16,  12,   8,  24,  58,  20,\n",
      "  22,  32,  56,  50,  52,  60,  54,  34]\n",
      "Length: 23, dtype: Int64\n",
      "------------------------\n",
      "Column 'orig_ip_bytes' has 46 unique values:\n",
      "<IntegerArray>\n",
      "[ 360,  240, 6032,  120,  112,  152,  176,   80,  192,  320,  336, 2972,  160,\n",
      "  352, 2362,  760, 2352, 2588,  968,  440,  720, 1236,  432, 1112,  224,  528,\n",
      "  480,  384, 2488,  200,  520, 2370, 2950,  840, 1000,  672, 2536, 2318, 2076,\n",
      " 2794, 3218, 2770, 2898,  880,  912, 2618]\n",
      "Length: 46, dtype: Int64\n",
      "------------------------\n",
      "Column 'resp_pkts' has 17 unique values:\n",
      "<IntegerArray>\n",
      "[0, 109, 2, 26, 36, 38, 40, 6, 4, 14, 8, 34, 18, 42, 46, 44, 12]\n",
      "Length: 17, dtype: Int64\n",
      "------------------------\n",
      "Column 'resp_ip_bytes' has 32 unique values:\n",
      "<IntegerArray>\n",
      "[     0, 155216,     80,    152,    104,   1444,   2118,   2472,   2304,\n",
      "    502,    168,     88,    328,    698,    402,   1666,   2588,   2126,\n",
      "    304,   1470,    126,     96,    120,   1016,   1990,   2714,   2334,\n",
      "   2778,   2490,   2642,    912,   1422]\n",
      "Length: 32, dtype: Int64\n",
      "------------------------\n",
      "Column 'label' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'detailed-label' has 6 unique values:\n",
      "[1 'C&C-HeartBeat-FileDownload' 'Attack' nan 'C&C-HeartBeat-Attack'\n",
      " 'C&C-PartOfAHorizontalPortScan']\n",
      "------------------------\n",
      "Column 'proto_icmp' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'proto_tcp' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'proto_udp' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_OTH' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_REJ' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_RSTO' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_RSTOS0' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_RSTR' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_S0' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'conn_state_S1' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_S2' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_SF' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_SH' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_D' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_Dd' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_F' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_R' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_S' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'history_SaR' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShADadfF' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAF' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAFr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdDaR' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdDaTFf' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdDaTR' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdDaTRf' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdDaTfR' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdDafr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdfr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAfFa' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAfFr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAfdtF' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShwA' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShwAr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_Sr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'service_dns' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'service_http' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# checks the unique values of all features\n",
    "for column in df43.columns:\n",
    "    unique_values = df43[column].unique()\n",
    "    print(f\"Column '{column}' has {len(unique_values)} unique values:\")\n",
    "    print(unique_values)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 54)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df43.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
