{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_43 = \"/Users/yujinkwon/Documents/CS334/Final_project/train_data_500k 1.csv\"\n",
    "capture_34 = \"/Users/yujinkwon/Documents/CS334/Final_project/opt/Malware-Project/BigDataset/IoTScenarios/CTU-IoT-Malware-Capture-34-1/bro/conn.log.labeled\"\n",
    "capture_60 = \"/Users/yujinkwon/Documents/CS334/Final_project/iot_malware_detection/data/60_train_data_500k.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data + Typecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df43 = pd.read_table(capture_60, skiprows = 2, delimiter='\\t', header =None) # for capture_43\n",
    "# df43 = pd.read_table(capture_34, skiprows = 8, delimiter='\\t', header =None) # for capture_34\n",
    "df43.columns = [\n",
    "    'ts',\t\n",
    "    'uid',\n",
    "    'id.orig_h',\n",
    "    'id.orig_p',\n",
    "    'id.resp_h',\n",
    "    'id.resp_p',\n",
    "    'proto',\n",
    "    'service',\n",
    "    'duration',\n",
    "    'orig_bytes',\n",
    "    'resp_bytes',\n",
    "    'conn_state',\n",
    "    'local_orig',\n",
    "    'local_resp',\n",
    "    'missed_bytes',\n",
    "    'history',\n",
    "    'orig_pkts',\n",
    "    'orig_ip_bytes',\n",
    "    'resp_pkts',\n",
    "    'resp_ip_bytes',\n",
    "    'last_col'\n",
    "]\n",
    "\n",
    "df43[['tunnel_parents', 'label', 'detailed-label']] = df43['last_col'].str.split(expand=True)\n",
    "df43.drop('last_col', axis=1, inplace=True)\n",
    "df43.drop('ts', axis=1, inplace=True)\n",
    "df43.drop('uid', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id.orig_h          object\n",
       "id.orig_p           int64\n",
       "id.resp_h          object\n",
       "id.resp_p           Int64\n",
       "proto              object\n",
       "service           float64\n",
       "duration          float64\n",
       "orig_bytes          Int64\n",
       "resp_bytes          Int64\n",
       "conn_state         object\n",
       "local_orig           bool\n",
       "local_resp           bool\n",
       "missed_bytes        int64\n",
       "history            object\n",
       "orig_pkts           Int64\n",
       "orig_ip_bytes       Int64\n",
       "resp_pkts           Int64\n",
       "resp_ip_bytes       Int64\n",
       "tunnel_parents    float64\n",
       "label              object\n",
       "detailed-label     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time\tstring\taddr\tport\taddr\tport\tenum\tstring\tinterval\tcount\tcount\tstring\tbool\tbool\tcount\tstring\tcount\tcount\tcount\tcount\tset[string]   string   string\n",
    "# df43['ts'] = pd.to_datetime(df43['ts'], unit = 's')\n",
    "\n",
    "\n",
    "# Replace 'NULL' with NaN (a common representation for missing values)\n",
    "df43.replace('-', 'NULL', inplace=True)\n",
    "df43.replace('NULL', np.nan, inplace=True)\n",
    "df43.replace('NaT', np.nan, inplace=True)\n",
    "df43.replace('NaN', np.nan, inplace=True)\n",
    "\n",
    "# Type casting features as correct type\n",
    "\n",
    "column_data = pd.to_numeric('duration', errors='coerce')\n",
    "df43['local_orig'] = df43['local_orig'].astype(bool)\n",
    "df43['local_resp'] = df43['local_resp'].astype(bool)\n",
    "df43['orig_bytes'] = df43['orig_bytes'].astype('Int64')\n",
    "df43['resp_bytes'] = df43['resp_bytes'].astype('Int64')\n",
    "df43['duration'] = df43['duration'].astype(float)\n",
    "df43['resp_bytes'] = df43['resp_bytes'].astype('Int64')\n",
    "df43['id.resp_p'] = df43['id.resp_p'].astype('Int64')\n",
    "df43['orig_pkts'] = df43['orig_pkts'].astype('Int64')\n",
    "df43['resp_pkts'] = df43['resp_pkts'].astype('Int64')\n",
    "df43['orig_ip_bytes'] = df43['orig_ip_bytes'].astype('Int64')\n",
    "df43['resp_ip_bytes'] = pd.to_numeric(df43['resp_ip_bytes'], errors='coerce')\n",
    "df43['resp_ip_bytes'] = df43['resp_ip_bytes'].astype('Int64')\n",
    "\n",
    "df43_clean = df43.copy()\n",
    "df43.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying port --> integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding id.orig_h, id.resp_h as Int64\n",
    "\n",
    "def port_to_int(df, col_name): \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for pnt in range(len(df43[col_name])):\n",
    "        if not pd.isna(df43.at[pnt, col_name]):\n",
    "            x = str(df43.at[pnt, col_name])  # Convert the numerical value to a string\n",
    "            z = ''\n",
    "            parts = x.split('.')\n",
    "            \n",
    "            # Process each part of the IP address-like value\n",
    "            for prt in range(4):\n",
    "                if len(parts[prt]) == 3:\n",
    "                    z = parts[prt] + z\n",
    "                elif len(parts[prt]) == 2:\n",
    "                    z = '0' + parts[prt] + z\n",
    "                else:\n",
    "                    z = '00' + parts[prt] + z\n",
    "            \n",
    "            # Update the DataFrame with the processed value\n",
    "            df43.at[pnt, col_name] = int(z)\n",
    "    \n",
    "    \n",
    "    return df43\n",
    "\n",
    "df43 = port_to_int(df43, 'id.orig_h')\n",
    "df43 = port_to_int(df43, 'id.resp_h')\n",
    "df43['id.orig_h'] = df43['id.orig_h'].astype('Int64')\n",
    "df43['id.resp_h'] = df43['id.resp_h'].astype('Int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id.orig_h           Int64\n",
       "id.orig_p           int64\n",
       "id.resp_h           Int64\n",
       "id.resp_p           Int64\n",
       "proto              object\n",
       "service           float64\n",
       "duration          float64\n",
       "orig_bytes          Int64\n",
       "resp_bytes          Int64\n",
       "conn_state         object\n",
       "local_orig           bool\n",
       "local_resp           bool\n",
       "missed_bytes        int64\n",
       "history            object\n",
       "orig_pkts           Int64\n",
       "orig_ip_bytes       Int64\n",
       "resp_pkts           Int64\n",
       "resp_ip_bytes       Int64\n",
       "tunnel_parents    float64\n",
       "label              object\n",
       "detailed-label     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df43.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Catgegorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_unique_vals(data, col):\n",
    "#     \"\"\"\n",
    "#     input is 2d numpy array of data, col name\n",
    "#     returns unqiue vals in column\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Extract the specified column\n",
    "#     column_data = data[col]\n",
    "\n",
    "#     # Find unique values in the column\n",
    "#     unique_values = np.unique(column_data)\n",
    "\n",
    "#     # Create a mapping from unique values to encoded integers\n",
    "#     value_to_int_map = {value: index for index, value in enumerate(unique_values)}\n",
    "\n",
    "#     # Encode the entire column using the mapping\n",
    "#     encoded_column = np.vectorize(value_to_int_map.get)(column_data)  \n",
    "\n",
    "#     data[col] = encoded_column\n",
    "\n",
    "#     return data\n",
    "\n",
    "# def encode_label(data, col):\n",
    "#     label_column = data[col]\n",
    "\n",
    "#     # Encode 'Benign' as 0 and other values as 1 using boolean indexing\n",
    "#     label_column[label_column == 'Benign'] = 0\n",
    "#     label_column[label_column != 0] = 1\n",
    "\n",
    "#     # Print modified label column\n",
    "#     print(\"Modified label column:\")\n",
    "#     print(label_column)\n",
    "\n",
    "#     # Update data array with the modified label column\n",
    "#     data[col] = label_column.astype(np.int32)  # Convert to float if necessary\n",
    "\n",
    "#     return data\n",
    "\n",
    "# def encode_detailed_label(data, col):\n",
    "#     label_column = data[col]\n",
    "    \n",
    "#     # Encode 'Benign' as 0 and other values as 1 using boolean indexing\n",
    "#     label_column[label_column == '-'] = 0\n",
    "#     label_column[label_column == 'PartOfAHorizontalPortScan'] = 1\n",
    "#     label_column[label_column == 'Benign'] = 2\n",
    "#     label_column[label_column == 'Benign'] = 3\n",
    "#     label_column[label_column == 'Benign'] = 4\n",
    "#     label_column[label_column == 'Benign'] = 5\n",
    "#     label_column[label_column == 'Benign'] = 6\n",
    "#     label_column[label_column == 'Benign'] = 7\n",
    "#     # Print modified label column\n",
    "#     print(\"Modified label column:\")\n",
    "#     print(label_column)\n",
    "\n",
    "#     # Update data array with the modified label column\n",
    "#     data[col] = label_column.astype(np.int32)  # Convert to float if necessary\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(data, col):\n",
    "\n",
    "    # Encode 'Benign' as 0 and other values as 1 using boolean indexing\n",
    "    data.loc[data[col] == 'Benign', col] = 0\n",
    "    data.loc[data[col] != 0, col] =  1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_detailed_label(data, col):\n",
    "\n",
    "    # Encode Detialed label based on type of malicious attack\n",
    "    data.loc[data[col] == np.nan, col] = 0\n",
    "    data.loc[data[col] == 'PartOfAHorizontalPortScan', col] = 1\n",
    "    data.loc[data[col] == 'Okiru', col] = 2\n",
    "    data.loc[data[col] == 'C&C', col] = 3\n",
    "    data.loc[data[col] == 'DDoS', col] = 4\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_column(df, column_name):\n",
    "    \"\"\"\n",
    "    One-hot encodes the unique values in the specified column of a DataFrame.\n",
    "    df: The input DataFrame.\n",
    "    column_name: The name of the column to be one-hot encoded.\n",
    "    \n",
    "    Returns: DataFrame with the specified column one-hot encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the specified column\n",
    "    column_data = df[column_name]\n",
    "    \n",
    "    # Use pd.get_dummies to one-hot encode the column\n",
    "    one_hot_encoded = pd.get_dummies(column_data, prefix=column_name)\n",
    "    \n",
    "    # Concatenate the one-hot encoded columns with the original DataFrame\n",
    "    df_encoded = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    \n",
    "    # Drop the original column as it's no longer needed\n",
    "    df_encoded = df_encoded.drop(column_name, axis=1)\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto\n",
      "conn_state\n",
      "history\n",
      "label\n",
      "detailed-label\n",
      "Index(['id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'duration',\n",
      "       'orig_bytes', 'resp_bytes', 'local_orig', 'local_resp', 'missed_bytes',\n",
      "       'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'label',\n",
      "       'detailed-label', 'proto_tcp', 'proto_udp', 'conn_state_OTH',\n",
      "       'conn_state_REJ', 'conn_state_RSTR', 'conn_state_S0', 'conn_state_SF',\n",
      "       'history_C', 'history_D', 'history_Dd', 'history_ShAdfDr', 'history_Sr',\n",
      "       'history_^c'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "mod_column_list = ['proto', 'conn_state', 'history', 'service']\n",
    "\n",
    "# Drop Nan Columns     \n",
    "# Check if any column contains only NaN values\n",
    "columns_with_allnan = df43.columns[df43.isna().all()]\n",
    "df43 = df43.drop(columns=columns_with_allnan)\n",
    "\n",
    "for mod_column in mod_column_list:\n",
    "    if mod_column in columns_with_allnan:\n",
    "        continue\n",
    "\n",
    "    print(mod_column)\n",
    "    df43 = one_hot_encode_column(df43, mod_column)\n",
    "\n",
    "mod_column = 'label'\n",
    "print(mod_column)\n",
    "df43 = encode_label(df43, mod_column)\n",
    "\n",
    "mod_column = 'detailed-label'\n",
    "print(mod_column)\n",
    "df34 = encode_detailed_label(df43, mod_column)\n",
    "\n",
    "print(df34.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'duration', 'orig_bytes', 'resp_bytes',  'missed_bytes', 'orig_pkts',  'orig_ip_bytes',  'resp_pkts',  'resp_ip_bytes']\n",
    "\n",
    "for col in col_list:\n",
    "    # Replace NaN values with the median\n",
    "    median_value = df43[col].median()\n",
    "    df43[col] = df43[col].fillna(median_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Dataframe into file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train500k_preproc.csv\"\n",
    "df43.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id.orig_h           Int64\n",
    "# id.orig_p           int64\n",
    "# id.resp_h           Int64\n",
    "# id.resp_p           Int64\n",
    "# proto              object\n",
    "# service           float64\n",
    "# duration          float64\n",
    "# orig_bytes          Int64\n",
    "# resp_bytes          Int64\n",
    "# conn_state         object\n",
    "# local_orig           bool\n",
    "# local_resp           bool\n",
    "# missed_bytes        int64\n",
    "# history            object\n",
    "# orig_pkts           Int64\n",
    "# orig_ip_bytes       Int64\n",
    "# resp_pkts           Int64\n",
    "# resp_ip_bytes       Int64\n",
    "# tunnel_parents    float64\n",
    "# label              object\n",
    "# detailed-label     object\n",
    "# dtype: object\n",
    "\n",
    "# Find columns with 'Int64' dtype\n",
    "int_columns = df43.select_dtypes(include='Int64').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data df43\n",
    "yData = df43[['label','detailed-label']]\n",
    "xData = df43.copy().drop(['label','detailed-label'],axis=1)\n",
    "\n",
    "xData.to_csv(\"60_500Kre_xTrain.csv\",index=False)\n",
    "yData.to_csv(\"60_500Kre_yTrain.csv\",index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'id.orig_h' has 2 unique values:\n",
      "<IntegerArray>\n",
      "[195001168192, 215088248162]\n",
      "Length: 2, dtype: Int64\n",
      "------------------------\n",
      "Column 'id.orig_p' has 65441 unique values:\n",
      "[37120 37122 37168 ... 62791  5433 32693]\n",
      "------------------------\n",
      "Column 'id.resp_h' has 13 unique values:\n",
      "<IntegerArray>\n",
      "[ 81048165102,  32254002081, 188210221089, 101218221089, 190030111212,\n",
      " 201099171173, 123056001005, 101134235068,  84195227105,  35074031031,\n",
      " 215088248162, 195001168192, 156033152075]\n",
      "Length: 13, dtype: Int64\n",
      "------------------------\n",
      "Column 'id.resp_p' has 45 unique values:\n",
      "<IntegerArray>\n",
      "[17769,   123,    80,  9307,  9306, 62336,   636,  8888,    81,  5269,    21,\n",
      "   135,    88,    25,  8000,    22,  5222,  5223,  2811, 20000,  3128,  6668,\n",
      "   445,   995,  1080,   587,   614,   990,    53,   563,  3389,   992,   502,\n",
      "   631,   993,  6669,  6667,   443,   585,   139,  8080,   143,   989,  6666,\n",
      " 53569]\n",
      "Length: 45, dtype: Int64\n",
      "------------------------\n",
      "Column 'duration' has 60 unique values:\n",
      "[1.84854900e+00 1.90251900e+00 1.88877800e+00 1.81755800e+00\n",
      " 1.85628700e+00 1.86029300e+00 9.27060000e-02 9.39540000e-02\n",
      " 9.27040000e-02 3.18684600e+00 9.27070000e-02 9.27030000e-02\n",
      " 5.53700000e-03 4.49600000e-03 7.49900000e-03 4.27100000e-03\n",
      " 8.24700000e-03 4.24700000e-03 4.00000000e-06 2.09044229e+02\n",
      " 3.00000000e-06 5.25000000e-03 3.50017109e+03 8.24800000e-03\n",
      " 7.49800000e-03 4.49700000e-03 2.00000000e-06 1.46444949e+03\n",
      " 5.00000000e-06 1.00045340e+01 1.00070340e+01 7.25000000e-03\n",
      " 4.49800000e-03 7.49600000e-03 5.24900000e-03 7.48500000e-03\n",
      " 5.48800000e-03 5.49800000e-03 7.48100000e-03 7.49700000e-03\n",
      " 7.74300000e-03 7.73200000e-03 4.73600000e-03 5.24800000e-03\n",
      " 7.74700000e-03 7.75100000e-03 7.74800000e-03 4.74800000e-03\n",
      " 9.98500000e-03 5.24700000e-03 7.49100000e-03 8.26500000e-03\n",
      " 4.48600000e-03 8.24500000e-03 4.48400000e-03 7.36550000e-03\n",
      " 5.49300000e-03 7.50600000e-03 8.24300000e-03 2.65090220e+01]\n",
      "------------------------\n",
      "Column 'orig_bytes' has 8 unique values:\n",
      "<IntegerArray>\n",
      "[518, 0, 96, 1124406, 16986360, 14319118, 576, 91360]\n",
      "Length: 8, dtype: Int64\n",
      "------------------------\n",
      "Column 'resp_bytes' has 6 unique values:\n",
      "<IntegerArray>\n",
      "[66, 0, 672, 96, 624, 576]\n",
      "Length: 6, dtype: Int64\n",
      "------------------------\n",
      "Column 'local_orig' has 1 unique values:\n",
      "[ True]\n",
      "------------------------\n",
      "Column 'local_resp' has 1 unique values:\n",
      "[ True]\n",
      "------------------------\n",
      "Column 'missed_bytes' has 1 unique values:\n",
      "[0]\n",
      "------------------------\n",
      "Column 'orig_pkts' has 9 unique values:\n",
      "<IntegerArray>\n",
      "[10, 2, 6, 1124406, 16986360, 14319118, 12, 0, 91360]\n",
      "Length: 9, dtype: Int64\n",
      "------------------------\n",
      "Column 'orig_ip_bytes' has 10 unique values:\n",
      "<IntegerArray>\n",
      "[1572, 120, 360, 152, 32607774, 492604440, 415254422, 912, 0, 2649440]\n",
      "Length: 10, dtype: Int64\n",
      "------------------------\n",
      "Column 'resp_pkts' has 6 unique values:\n",
      "<IntegerArray>\n",
      "[8, 2, 14, 13, 0, 12]\n",
      "Length: 6, dtype: Int64\n",
      "------------------------\n",
      "Column 'resp_ip_bytes' has 7 unique values:\n",
      "<IntegerArray>\n",
      "[540, 80, 1064, 152, 988, 0, 912]\n",
      "Length: 7, dtype: Int64\n",
      "------------------------\n",
      "Column 'label' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'detailed-label' has 3 unique values:\n",
      "['C&C-HeartBeat' nan 4]\n",
      "------------------------\n",
      "Column 'proto_tcp' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'proto_udp' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_OTH' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_REJ' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_RSTR' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'conn_state_S0' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'conn_state_SF' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_C' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_D' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_Dd' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_ShAdfDr' has 2 unique values:\n",
      "[1 0]\n",
      "------------------------\n",
      "Column 'history_Sr' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n",
      "Column 'history_^c' has 2 unique values:\n",
      "[0 1]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# checks the unique values of all features\n",
    "for column in df43.columns:\n",
    "    unique_values = df43[column].unique()\n",
    "    print(f\"Column '{column}' has {len(unique_values)} unique values:\")\n",
    "    print(unique_values)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 29)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df43.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
